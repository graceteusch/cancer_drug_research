{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ftplib import FTP\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in supplementary table\n",
    "drugInfo = pd.read_csv(\"Drug_Info_Supp_Table.csv\")\n",
    "drugInfo[\"Drug\"] = drugInfo[\"Drug\"].str.strip()\n",
    "\n",
    "#group all drugs by their type and turn into dictionary\n",
    "drugTypes = drugInfo.groupby(\"Type\")[\"Drug\"].apply(list).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a table with all mean intensity values for all of the drugs\n",
    "allDrugs = drugInfo[\"Drug\"].to_list()\n",
    "combined = pd.DataFrame(columns=[\"gene\"])\n",
    "\n",
    "# set up FTP \n",
    "ftp = FTP(\"massive-ftp.ucsd.edu\")\n",
    "ftp.login()\n",
    "ftp.cwd(\"/v06/MSV000093659/other/Dose response data - Jurkat proteome\")\n",
    "\n",
    "for drug in allDrugs:\n",
    "    # make a string with the drug name + _ALL.txt \n",
    "    drugFileName = f\"{drug}_ALL.txt\"\n",
    "\n",
    "    # check if the file already exists locally (already downloaded it)\n",
    "    if not os.path.exists(drugFileName):\n",
    "\n",
    "        # if it doesn't already exist, use FTP to get that file from the server\n",
    "        drugPath = f\"{drug}/TXTs_Classified\"\n",
    "        ftp.cwd(drugPath)\n",
    "        \n",
    "        # download/write the file in binary mode\n",
    "        with open(drugFileName, \"wb\") as file:\n",
    "        # download the file \"RETR fileName\"\n",
    "            ftp.retrbinary(f\"RETR {drugFileName}\", file.write)\n",
    "        \n",
    "        # move back to the Jurkat proteome directory\n",
    "        ftp.cwd(\"../../\")\n",
    "\n",
    "    # load the file as a dataframe\n",
    "    drugData = pd.read_csv(drugFileName, delimiter = \"\\t\") \n",
    "\n",
    "    # select the gene and mean intensity columns  \n",
    "    meanData = drugData[[\"gene\", \"Mean_Intensity\"]]\n",
    "    # rename mean intensity column to include the name of the drug\n",
    "    renamedData = meanData.rename(columns = {\"Mean_Intensity\":f\"{drug}_Mean_Intensity\"})\n",
    "    # add both of those columns to a combined dataframe (Created before the for loop)\n",
    "    combined = pd.merge(combined, renamedData, how = \"outer\", on = \"gene\")\n",
    "\n",
    "ftp.quit()\n",
    "combined.set_index(\"gene\")\n",
    "combined.head()\n",
    "combined.to_csv(\"Mean_Intensity_Matrix_All_Drugs.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make separate files for mean intensity values based on drug types \n",
    "\n",
    "# get combined matrix of values and rename columns to just be the drug names\n",
    "meanIntensityMatrix = combined\n",
    "meanIntensityMatrix.columns = meanIntensityMatrix.columns.str.removesuffix(\"_Mean_Intensity\")\n",
    "\n",
    "# make empty dict for dataframes by type\n",
    "# keys: drug types, values: dfs of mean intensity vals for drugs in that type\n",
    "meansByDrugType = {}\n",
    "\n",
    "# loop through the dictionary of types and drugs\n",
    "for type, drugNames in drugTypes.items():\n",
    "    # select columns in the combined matrix for all the drugs in that type\n",
    "    typeSubset = meanIntensityMatrix[drugNames]\n",
    "    # save those columns to the dict of types/values\n",
    "    meansByDrugType[type] = typeSubset\n",
    "\n",
    "# # print out meansByDrugType dictionary:\n",
    "# for type, df in meansByDrugType.items():\n",
    "#     print(f\"type: {type}\\n{df.head()}\")\n",
    "\n",
    "# save the df for each type as a csv \n",
    "for type, df in meansByDrugType.items():\n",
    "    df.to_csv(f\"Mean_Intensity_Matrix_{type}.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make separate files for ic50 values based on drug types\n",
    "# OR, use the table from salma â€”> go thru the dict by drug type, select all the columns for the drugs in that type and\n",
    "    # save them in a new data frame with the name of that drug type. \n",
    "\n",
    "# get combined matrix of values\n",
    "ic50Matrix = pd.read_csv(\"ic50_matrix.csv\")\n",
    "\n",
    "# make empty dict for dataframes by type\n",
    "# keys: drug types, values: dfs of ic50 vals for drugs in that type\n",
    "ic50sByDrugType = {}\n",
    "\n",
    "#read in supplementary table\n",
    "# drugInfo = pd.read_csv(\"Drug_Info_Supp_Table.csv\")\n",
    "drugInfoWithUnderscores = drugInfo\n",
    "drugInfoWithUnderscores[\"Drug\"] = drugInfo[\"Drug\"].str.replace(' ', '_')\n",
    "\n",
    "#group all drugs by their type and turn into dictionary\n",
    "drugTypesWithUnderscores = drugInfoWithUnderscores.groupby(\"Type\")[\"Drug\"].apply(list).to_dict()\n",
    "\n",
    "# loop through the dictionary of types and drugs\n",
    "for type, drugNames in drugTypesWithUnderscores.items():\n",
    "    # select columns in the combined matrix for all the drugs in that type\n",
    "    df = ic50Matrix[drugNames]\n",
    "    # save those columns to the dict of types/values\n",
    "    ic50sByDrugType[type] = df\n",
    "\n",
    "# save the df for each type as a csv \n",
    "for type, df in ic50sByDrugType.items():\n",
    "    df.to_csv(f\"ic50_Matrix_{type}.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
